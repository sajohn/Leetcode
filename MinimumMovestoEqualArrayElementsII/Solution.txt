public class Solution {
    public int minMoves2(int[] nums) {
        long ans = Long.MAX_VALUE;
        int minval = Integer.MAX_VALUE;
        int maxval = Integer.MIN_VALUE;
        for (int num : nums) {
            minval = Math.min(minval, num);
            maxval = Math.max(maxval, num);
        }
        for (int i = minval; i <= maxval; i++) {
            long sum = 0;
            for (int num : nums) {
                sum += Math.abs(num - i);
            }
            ans = Math.min(ans, sum);
        }
        return (int) ans;
    }
}
public class Solution {
    public int minMoves2(int[] nums) {
        long min = Integer.MAX_VALUE;
        for (int num : nums) {
            long sum = 0;
            for (int n : nums) {
                sum += Math.abs(n - num);
            }
            min = Math.min(min, sum);
        }
        return (int) min;
    }
}

public class Solution {
    public int minMoves2(int[] nums) {
        Arrays.sort(nums);
        long min = Long.MAX_VALUE, sum = 0, total = 0;
        for (int num : nums) {
            total += num;
        }
        for (int i = 0; i < nums.length; i++) {
            long ans = ((long) nums[i] * i - sum) + ((total - sum) - (long) nums[i] * (nums.length - i));
            System.out.println(nums[i] + " " + ans);
            min = Math.min(min, ans);
            sum += nums[i];
        }
        return (int) min;
    }
}

public class Solution {
    public int minMoves2(int[] nums) {
        Arrays.sort(nums);
        int sum = 0;
        for (int num : nums) {
            sum += Math.abs(nums[nums.length / 2] - num);
        }
        return sum;
    }
}

public class Solution {
    public int minMoves2(int[] nums) {
        int l = 0, r = nums.length - 1, sum = 0;
        Arrays.sort(nums);
        while (l < r) {
            sum += nums[r] - nums[l];
            l++;
            r--;
        }
        return sum;
    }
}

public class Solution {
    public void swap(int[] list, int i, int pivot_index) {
        int temp = list[i];
        list[i] = list[pivot_index];
        list[pivot_index] = temp;
    }
    public int partition(int[] list, int left, int right) {
        int pivotValue = list[right];
        int i = left;
        for (int j = left; j <= right; j++) {
            if (list[j] < pivotValue) {
                swap(list, i, j);
                i++;
            }
        }
        swap(list, right, i);
        return i;
    }
    int select(int[] list, int left, int right, int k) {
        if (left == right) {
            return list[left];
        }
        int pivotIndex = partition(list, left, right);
        if (k == pivotIndex) {
            return list[k];
        } else if (k < pivotIndex) {
            return select(list, left, pivotIndex - 1, k);
        } else {
            return select(list, pivotIndex + 1, right, k);
        }
    }
    public int minMoves2(int[] nums) {
        int sum = 0;
        int median = select(nums, 0, nums.length - 1, nums.length / 2);

        for (int num : nums) {
            sum += Math.abs(median - num);
        }
        return sum;
    }
}

Solution
Approach 1: Brute Force
In the brute force approach, we consider every possible number to which all the array elements should be equated so as to minimize the number of moves required. One point is obvious that the number to which all the elements are equated at the end should lie between the minimum and the maximum elements present in the array. Thus, we first find the minimum and the maximum element in the array. Suppose kk is the number to which all the elements are equated. Then, we iterate kk over the range between the minimum and maximum values and find the number of moves required for each kk, simultaneously finding the minimum moves, which will be the end result.


Complexity Analysis

Time complexity : O(n \cdot \text{diff})O(n⋅diff), where nn is the length of the array and \text{diff}diff is the difference between maximum element and minimum element.
Space complexity : O(1)O(1). No extra space required.
Approach 2: Better Brute Force
Algorithm

In this approach, rather than choosing every possible kk between the minimum and the maximum values in the array, we can simply consider kk as every element of the array. To understand why we need not iterate over all the complete range but only the elements of the array, consider the following example.

Say the array is:

mums = [x_1 x_2 x_3 x_4 x_5 x_6 x_7]mums=[x 
1
​	
 x 
2
​	
 x 
3
​	
 x 
4
​	
 x 
5
​	
 x 
6
​	
 x 
7
​	
 ]. Now, if we try to equalize all the elements to x_4x 
4
​	
 , which by the way, may or may not be the final number required to be settled down to.

The total number of moves for doing this is given by: moves_1 = (x_4 - x_1) + (x_4 - x_2) + (x_4 - x_3) + (x_5 - x_4) + (x_6 - x_4) + (x_7 - x_4)moves 
1
​	
 =(x 
4
​	
 −x 
1
​	
 )+(x 
4
​	
 −x 
2
​	
 )+(x 
4
​	
 −x 
3
​	
 )+(x 
5
​	
 −x 
4
​	
 )+(x 
6
​	
 −x 
4
​	
 )+(x 
7
​	
 −x 
4
​	
 )

Suppose, now, instead of x_4x 
4
​	
 , we try to equalize all the elements to a number x'x 
′
 , which is not present in the given array, but is slightly larger than x_4x 
4
​	
  and is thus given by say x' = x_4 + \delta xx 
′
 =x 
4
​	
 +δx, where \delta xδx is an integer. Thus, the total number of moves required now will be given by:

moves_2 = (x' - x_1) + (x' - x_2) + (x' - x_3) + (x' - x_4) + (x_5 - x') + (x_6 - x') + (x_7 - x')moves 
2
​	
 =(x 
′
 −x 
1
​	
 )+(x 
′
 −x 
2
​	
 )+(x 
′
 −x 
3
​	
 )+(x 
′
 −x 
4
​	
 )+(x 
5
​	
 −x 
′
 )+(x 
6
​	
 −x 
′
 )+(x 
7
​	
 −x 
′
 )

moves_2 = ((x_4 + \delta x) - x_1) + ((x_4 + \delta x) - x_2) + ((x_4 + \delta x) - x_3) + ((x_4 + \delta x) - x_4) + (x_5 - (x_4 + \delta x)) + (x_6 - (x_4 + \delta x)) + (x_7 - (x_4 + \delta x))moves 
2
​	
 =((x 
4
​	
 +δx)−x 
1
​	
 )+((x 
4
​	
 +δx)−x 
2
​	
 )+((x 
4
​	
 +δx)−x 
3
​	
 )+((x 
4
​	
 +δx)−x 
4
​	
 )+(x 
5
​	
 −(x 
4
​	
 +δx))+(x 
6
​	
 −(x 
4
​	
 +δx))+(x 
7
​	
 −(x 
4
​	
 +δx))

moves_2 = (x_4 - x_1) + \delta x + (x_4 - x_2) + \delta x + (x_4 - x_3) + \delta x + 0 + \delta x + (x_5 - x_4) - \delta x + (x_6 - x_4) - \delta x + (x_7 - x_4) - \delta xmoves 
2
​	
 =(x 
4
​	
 −x 
1
​	
 )+δx+(x 
4
​	
 −x 
2
​	
 )+δx+(x 
4
​	
 −x 
3
​	
 )+δx+0+δx+(x 
5
​	
 −x 
4
​	
 )−δx+(x 
6
​	
 −x 
4
​	
 )−δx+(x 
7
​	
 −x 
4
​	
 )−δx

moves_2 = (x_4 - x_1) + (x_4 - x_2) + (x_4 - x_3) + (x_5 - x_4) + (x_6 - x_4) + (x_7 - x_4) + 4\delta x - 3\delta xmoves 
2
​	
 =(x 
4
​	
 −x 
1
​	
 )+(x 
4
​	
 −x 
2
​	
 )+(x 
4
​	
 −x 
3
​	
 )+(x 
5
​	
 −x 
4
​	
 )+(x 
6
​	
 −x 
4
​	
 )+(x 
7
​	
 −x 
4
​	
 )+4δx−3δx

moves_2 = moves_1 + \delta xmoves 
2
​	
 =moves 
1
​	
 +δx ...using moves_1moves 
1
​	
  from above

From this equation, it is clear that the number of moves required to settle to some arbitrary number present in the array x_4x 
4
​	
  is always lesser than the number of moves required to settle down to some arbitrary number x' = x_4 + \delta xx 
′
 =x 
4
​	
 +δx. This completes the proof.


Complexity Analysis

Time complexity : O(n^2)O(n 
2
 ). Two nested loops are there.

Space complexity : O(1)O(1). No extra space required.

Approach 3: Using Sorting
Algorithm

In the previous approach, we needed to find the number of moves required for every kk chosen from the array, by iterating over the whole array. We can optimize this approach to sum extent by sorting the array and observing the following fact. The number of moves required to raise the elements smaller than kk to equalize them to kk will be given by: (k*countBefore_k) - (sumBefore_k)(k∗countBefore 
k
​	
 )−(sumBefore 
k
​	
 )(The meanings of the keywords are given below) . Similarly, the number of moves required to decrement the elements larger than kk to equalize them to kk will be: (sumAfter_k) - (k*countAfter_k)(sumAfter 
k
​	
 )−(k∗countAfter 
k
​	
 ). The total number of moves required will, thus, be the sum of these two parts. Hence, for a particular kk chosen, the total number of moves required will be given by:

numberOfMoves_k = [(k*countBefore_k) - (sumBefore_k)] + [(sumAfter_k) - (k*countAfter_k)]numberOfMoves 
k
​	
 =[(k∗countBefore 
k
​	
 )−(sumBefore 
k
​	
 )]+[(sumAfter 
k
​	
 )−(k∗countAfter 
k
​	
 )]

where, kk = The number to which all the elements are equalized at the end.

countBefore_kcountBefore 
k
​	
  = The number of elements which are lesser than kk.

sumBefore_ksumBefore 
k
​	
  = The sum of elements which are lesser than kk.

countAfter_kcountAfter 
k
​	
  = The number of elements which are larger than kk.

sumAfter_ksumAfter 
k
​	
  = The sum of elements which are larger than kk.

numberOfMoves_knumberOfMoves 
k
​	
  = The total number of moves required to equalize all the elements of the array to kk.

Let's say that the index of the element corresponding to the element kk be given by index_kindex 
k
​	
 . Instead of iterating over the array for calculating sumBefore_ksumBefore 
k
​	
  and sumAfter_ksumAfter 
k
​	
 , we can keep on calculating them while traversing the array since the array is sorted. We calculate the total sum of the given array numsnums once, given by totaltotal. We start by choosing sumBefore_k=0sumBefore 
k
​	
 =0 and sumAfter_ksumAfter 
k
​	
  as totaltotal. To calculate sumBefore_ksumBefore 
k
​	
 , we just add the element nums[index_k - 1]nums[index 
k
​	
 −1] to the previous sumBefore_ksumBefore 
k
​	
 . To calculate sumAfter_ksumAfter 
k
​	
 , we subtract the element kk from the previous sumAfter_ksumAfter 
k
​	
 .


Complexity Analysis

Time complexity : O\big(n\log n\big)O(nlogn). Sorting will take O\big(n\log n\big)O(nlogn) time.

Space complexity : O(1)O(1). No extra space required.

Approach 4: Using Median and Sorting
Algorithm

The problem of finding the number kk to which all the other numbers eventually settle can also be viewed as: Given a set of points in 1-d. Find a point kk such that the cumulative sum of distances between kk and the rest of the points is minimum. This is a very common mathematical problem whose answer is known. The point kk is the median of the given points. The reason behind choosing the median is given after the algorithm.

We can simply sort the given points and find the medianmedian as the element in the middle of the array. Thus, the total number of moves required to equalize all the array elements is given by the sum of differences of all the elements from the medianmedian. In mathematical terms, the solution is given by:

moves = \sum_{i=0}^{n-1} |median - nums[i]|moves=∑ 
i=0
n−1
​	
 ∣median−nums[i]∣ , where nn is the size of the given array.

Current
1 / 8
Now, we'll look at the mathematical reasoning behind choosing the median as the number kk to which we'll settle. As discussed in the previous approach, the total number of moves required is given by:

numberOfMoves_k = [(k*countBefore_k) - (sumBefore_k)] + [(sumAfter_k) - (k*countAfter_k)]numberOfMoves 
k
​	
 =[(k∗countBefore 
k
​	
 )−(sumBefore 
k
​	
 )]+[(sumAfter 
k
​	
 )−(k∗countAfter 
k
​	
 )], where all the variables have the same definition.

Now, as we know, in order to maximize this term w.r.t. the changes in kk, we can take the derivative of the above term w.r.t. kk. Thus, we proceed as:

\frac{d(numberOfMoves_k)}{dk} = \frac{[(k*countBefore_k) - (sumBefore_k)] + [(sumAfter_k) - (k*countAfter_k)]}{dk} 
dk
d(numberOfMoves 
k
​	
 )
​	
 = 
dk
[(k∗countBefore 
k
​	
 )−(sumBefore 
k
​	
 )]+[(sumAfter 
k
​	
 )−(k∗countAfter 
k
​	
 )]
​	
 

\frac{d(numberOfMoves_k)}{dk} = \frac{(k*countBefore_k)}{dk} - \frac{d(sumBefore_k)}{dk} + \frac{d(sumAfter_k)}{dk} - \frac{(k*countAfter_k)}{dk} 
dk
d(numberOfMoves 
k
​	
 )
​	
 = 
dk
(k∗countBefore 
k
​	
 )
​	
 − 
dk
d(sumBefore 
k
​	
 )
​	
 + 
dk
d(sumAfter 
k
​	
 )
​	
 − 
dk
(k∗countAfter 
k
​	
 )
​	
 

\frac{d(numberOfMoves_k)}{dk} = countBefore_k - countAfter_k 
dk
d(numberOfMoves 
k
​	
 )
​	
 =countBefore 
k
​	
 −countAfter 
k
​	
 

Setting derivative \frac{d(numberOfMoves_k)}{dk} 
dk
d(numberOfMoves 
k
​	
 )
​	
  equal to 00, we get:

countBefore_k - countAfter_k = 0countBefore 
k
​	
 −countAfter 
k
​	
 =0 or countBefore_k = countAfter_kcountBefore 
k
​	
 =countAfter 
k
​	
 . This property is satisfied by the median only, which completes the proof.


Complexity Analysis

Time complexity : O\big(n\log n\big)O(nlogn). Sorting will take O\big(n\log n\big)O(nlogn) time.

Space complexity : O(1)O(1). Only single extra variable is used.

Approach 5: Without Finding Median
Algorithm

In the previous approach, we went for finding the median after sorting and then calculated the number of moves required. But, if we observe properly, we'll find that if the array is sorted, we can do the same task without actually finding the median or the number kk to which we need to settle at the end. To proceed with this, let's look at the maximum(maxmax) and the minimum numbers(minmin) in the array, which currently lie at its extreme positions. We know, at the end, both these numbers should be equalized to kk. For the number maxmax, the number of moves required to do this is given by max - kmax−k. Similarly, for the number minmin, the number of moves is given by k - mink−min. Thus, the total number of moves for both maxmax and minmin is given by max - k + (k - min) = max - minmax−k+(k−min)=max−min, which is independent of the number kk. Thus, we can continue now, with the next maximum and the next minimum number in the array, until the complete array is exhausted.

Therefore, the equation becomes:

moves = \sum_{i=0}^{\left \lceil{\frac{n}{2}} \right \rceil - 1} |nums[n-i] - nums[i]|moves=∑ 
i=0
⌈ 
2
n
​	
 ⌉−1
​	
 ∣nums[n−i]−nums[i]∣, where nn is the number of elements in the array numsnums.


Complexity Analysis

Time complexity : O\big(n\log n\big)O(nlogn). Sorting will take O\big(n\log n\big)O(nlogn) time.

Space complexity : O(1)O(1). No extra space required.

Approach 6: Using Quick-Select
Algorithm

In order to find the median, we need not necessarily sort the given array. But we can find the median directly using the Quick-Select method to find the median, which doesn't use sorting.

The quick-select method is similar to the Quick-Sort method. In a single iteration, we choose a pivot and somehow bring it to its correct position in the array. If the correct position happens to be the central position(corresponding to the median), we can return the median directly from there. Now, let's look at the implementation of quick-select.

Quick-Select makes use of two functions partitionpartition and selectselect. selectselect function takes the leftmost and the rightmost indices of the given array and the central index as well. If the element reaching the correct position in the current function call to selectselect function happens to be the median(i.e. it reaches the central position), we return the element(since it is the median). The function partitionpartition takes the leftmost and the rightmost indices of the array and returns the correct position of the current pivot(which is chosen as the rightmost element of the array). This function makes use of two pointers ii and jj. Both the pointers initially point to the leftmost element of the array.

At every step, we compare the element at the j^{th}j 
th
  index(list[j]list[j]) with the pivot element(pivotpivot). If list[j]<pivotlist[j]<pivot, we swap the elements list[i]list[i] and list[j]list[j] and increment ii and jj. Otherwise, only jj is incremented. When jj reaches the end of the array, we swap the pivotpivot with list[i]list[i]. In this way, now, all the elements lesser than pivotpivot lie to the left of the i^{th}i 
th
  index, and all the elements larger than pivotpivot lie to the right of the i^{th}i 
th
  index and thus, the pivotpivot reaches at its correct position in the array. If this position isn't the central index of the array, we again make use of the selectselect functions passing the left and the right subarrays relative to the i^{th}i 
th
  index.

For more clarification, look at the animation below for this example:

[3 8 2 5 1 4 7 6]
Current
1 / 16
After finding the median, we can find the sum of absolute differences of all the elements from the median to determine the number of moves required. Mathematically, we use:

moves = \sum_{i=0}^{n-1} |median - list[i]|moves=∑ 
i=0
n−1
​	
 ∣median−list[i]∣ , where nn is the size of the given array.


Complexity Analysis

Time complexity : Average Case: O(n)O(n). Quick-Select average case time complexity is O(n)O(n). Worst Case: O(n^2)O(n 
2
 ). In worst case quick-select can go upto n^2n 
2
 

Space complexity : O(1)O(1). No extra space required.

Approach 7: Using Median of Medians
Algorithm

It isn't hard to see that, in quick-select, if we naively choose the pivot element, this algorithm has a worst case performance of O(n^2)O(n 
2
 ). To guarantee the linear running time in order to find the median, however we need a strategy for choosing the pivot element that guarantees that we partition the list into two sublists of relatively comparable size. Obviously the median of the values in the list would be the optimal choice, but if we could find the median in linear time, we would already have a solution to our problem.

The median-of-medians algorithm chooses its pivot in the following clever way:

kthSmallest(arr[0..n-1], k)kthSmallest(arr[0..n−1],k)

Divide arr[]arr[] into \left \lceil{\frac{n}{5}}\right\rceil⌈ 
5
n
​	
 ⌉ groups where size of each group is 5 elements, except possibly the last group which may have less than 5 elements.

Sort the above created \left \lceil{\frac{n}{5}}\right\rceil⌈ 
5
n
​	
 ⌉ groups and find median of all groups. Create an auxiliary array median[]median[] and store medians of all \left \lceil{\frac{n}{5}}\right\rceil⌈ 
5
n
​	
 ⌉ groups in this median array. Also, recursively call this method to find median of median[0...(\left \lceil{\frac{n}{5}}\right\rceil - 1)(⌈ 
5
n
​	
 ⌉−1)]

\text{medOfMed} = kthSmallest\big(median[0...(\left \lceil{\frac{n}{5}}\right\rceil - 1)], \left \lceil{\frac{n}{10}}\right\rceil\big)medOfMed=kthSmallest(median[0...(⌈ 
5
n
​	
 ⌉−1)],⌈ 
10
n
​	
 ⌉)

Partition arr[]arr[] around \text{medOfMed}medOfMed and obtain its position(i.e. use \text{medOfMed}medOfMed as the pivot element). pos = partition(arr, n, \text{medOfMed})pos=partition(arr,n,medOfMed)

If pos == kpos==k return \text{medOfMed}medOfMed

If pos < kpos<k return kthSmallest(arr[l..pos-1], k)kthSmallest(arr[l..pos−1],k)

If pos > kpos>k return kthSmallest(arr[pos+1..r], k-pos+l-1)kthSmallest(arr[pos+1..r],k−pos+l−1)

Using the above method ensures that the chosen pivot, in the worst case, has atmost 70% elements which are larger/smaller than the pivot. The proof of the same as well as the reason behind choosing the group size of 5 is given in the explanation of time complexity.


Complexity Analysis

Time complexity : O(n)O(n). Worst case time complexity is O(n)O(n).

Space complexity : O(n)O(n) to keep medians array of at most (n + 4) / 5 elements.

Proof: Time Complexity O(n)O(n):

The worst case time complexity of the above algorithm is O(n)O(n). Let us analyze all steps.

The steps 1. and 2. take O(n)O(n) time as finding median of an array of size 5 takes O(1) time and there are \left \lceil{\frac{n}{5}}\right\rceil⌈ 
5
n
​	
 ⌉ such arrays. The step 3. takes T(n/5)T(n/5) time(if the whole algorithm takes T(n)T(n) time). The step 4. is standard partition and takes O(n)O(n) time. The interesting steps are 6. and 7. At most, one of them is executed. These are recursive steps. What is the worst case size of these recursive calls? The answer is maximum number of elements greater than \text{medOfMed}medOfMed (obtained in step 3) or maximum number of elements smaller than \text{medOfMed}medOfMed.

How many elements are greater than \text{medOfMed}medOfMed and how many are smaller?

Let's assume that the list of medians obtained from step 2. in the sorted order be m_1, m_2, m_3,....,m_{x-1}, m_x, m_{x+1} ...m_{n-2}, m_{n-1}, m_nm 
1
​	
 ,m 
2
​	
 ,m 
3
​	
 ,....,m 
x−1
​	
 ,m 
x
​	
 ,m 
x+1
​	
 ...m 
n−2
​	
 ,m 
n−1
​	
 ,m 
n
​	
 , where m_xm 
x
​	
  is the median chosen as the pivot. To find an upper bound on the number of elements in the given array smaller than our pivot, first consider the half of the medians from step 2(m_1, m_2, ..., m_{x-1}m 
1
​	
 ,m 
2
​	
 ,...,m 
x−1
​	
 ) which are smaller than the pivot. It is possible for all five of the elements in the sublists corresponding to these medians to be smaller than the pivot(m_xm 
x
​	
 , which leads to an upper bound of \left \lceil{\frac{n}{5}}\right\rceil*5*\frac{1}{2}⌈ 
5
n
​	
 ⌉∗5∗ 
2
1
​	
  such elements. Now consider the half of the medians from step 2 which are larger than the pivot (m_{x+1}, ..., m_{n-1}, m_nm 
x+1
​	
 ,...,m 
n−1
​	
 ,m 
n
​	
 ). It is only possible for two of the elements(which are smaller than the respective medians) in the sublists corresponding to these medians to be smaller than the pivot(m_xm 
x
​	
 ), which leads to an upper bound of \left \lceil{\frac{n}{5}}\right\rceil*2*\frac{1}{2} = \left \lceil{\frac{n}{5}}\right\rceil⌈ 
5
n
​	
 ⌉∗2∗ 
2
1
​	
 =⌈ 
5
n
​	
 ⌉ such elements. In addition, the sublist containing the pivot(m_xm 
x
​	
 ) contributes exactly two elements smaller than the pivot. It total, we may have at most:

\frac{5}{2}\left \lceil{\frac{n}{5}}\right\rceil + \left \lceil{\frac{n}{5}}\right\rceil + 2 = \frac{7}{2}\left \lceil{\frac{n}{5}}\right\rceil + 2 \leq \frac{7n}{10} + 6 
2
5
​	
 ⌈ 
5
n
​	
 ⌉+⌈ 
5
n
​	
 ⌉+2= 
2
7
​	
 ⌈ 
5
n
​	
 ⌉+2≤ 
10
7n
​	
 +6

elements smaller than the pivot, or approximately 70% of the list. The same upper bound applies the the number of elements in the list larger than the pivot. It is this guarantee that the partitions cannot be too lopsided that leads to linear run time.

Thus, the minimum number of elements which are smaller or larger than the chosen pivot(\text{medOfMed}medOfMed) is given by n - (\frac{7n}{10} + 6) = \frac{3n}{10} - 6n−( 
10
7n
​	
 +6)= 
10
3n
​	
 −6 or nearly 30% of the elements.

In the worst case, the function recurs for at most \frac{7n}{10} + 6 
10
7n
​	
 +6 times.

Note that \frac{7n}{10} + 6 < n 
10
7n
​	
 +6<n for n > 20n>20 and that any input of 80 or fewer elements requires O(1)O(1) time. We can therefore obtain the recurrence:

T(n) \leq \begin{cases} \Theta(1), & n\leq80 \\ T\left \lceil\frac{n}{5}\right\rceil + T(\frac{7n}{10} + 6) + O(n), & n>80 \end{cases}T(n)≤{ 
Θ(1),
T⌈ 
5
n
​	
 ⌉+T( 
10
7n
​	
 +6)+O(n),
​	
  
n≤80
n>80
​	
 

We show that the running time is linear by substitution. Assume that T(n) = c \cdot nT(n)=c⋅n for some constant cc and all n > 80n>80. Substituting this inductive hypothesis into the right-hand side of the recurrence yields

T(n) \leq \frac{cn}{5} + c(\frac{7n}{10} + 6) + O(n)T(n)≤ 
5
cn
​	
 +c( 
10
7n
​	
 +6)+O(n) \leq \frac{cn}{5} + c + \frac{7cn}{10} + 6c + O(n)≤ 
5
cn
​	
 +c+ 
10
7cn
​	
 +6c+O(n) \leq \frac{9cn}{10} + 7c + O(n)≤ 
10
9cn
​	
 +7c+O(n) \leq cn≤cn since we can pick c large enough so that c(\frac{n}{10} - 7)c( 
10
n
​	
 −7) is larger than the function described by the O(n)O(n) term for all n > 80n>80. The worst-case running time of is therefore linear.

Choosing the group size of 3 leads to at least half of the n/3 blocks having at least 2 elements \geq \text{medOfMed}≥medOfMed, hence this gives a n/3 split, or 2n/3 in the worst case.

This gives T(n)T(n) = T(\frac{n}{3}) + T(\frac{2n}{3}) + O(n)T( 
3
n
​	
 )+T( 
3
2n
​	
 )+O(n), which reduces to O(n\log n)O(nlogn) in the worst case.

There is no reason why you should not use something greater than five; for example with seven the inequality would be

T(n) \leq T(\frac{n}{7})+T(\frac{5n}{7})+O(n)T(n)≤T( 
7
n
​	
 )+T( 
7
5n
​	
 )+O(n)

T(n) \leq T(\frac{n}{7})+T(\frac{5n}{7})+O(n)T(n)≤T( 
7
n
​	
 )+T( 
7
5n
​	
 )+O(n)

which also works, but five is the smallest odd number (useful for medians) which works.
